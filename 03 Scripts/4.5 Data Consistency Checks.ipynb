{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e7f2c1e8-0c76-4829-9489-c0d68f1ab916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>order_number</th>\n",
       "      <th>order_day_of_week</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.421083e+06</td>\n",
       "      <td>3.421083e+06</td>\n",
       "      <td>3.421083e+06</td>\n",
       "      <td>3.421083e+06</td>\n",
       "      <td>3.421083e+06</td>\n",
       "      <td>3.421083e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.710542e+06</td>\n",
       "      <td>1.029782e+05</td>\n",
       "      <td>1.715486e+01</td>\n",
       "      <td>2.776219e+00</td>\n",
       "      <td>1.345202e+01</td>\n",
       "      <td>1.111484e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.875817e+05</td>\n",
       "      <td>5.953372e+04</td>\n",
       "      <td>1.773316e+01</td>\n",
       "      <td>2.046829e+00</td>\n",
       "      <td>4.226088e+00</td>\n",
       "      <td>8.924952e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.552715e+05</td>\n",
       "      <td>5.139400e+04</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.710542e+06</td>\n",
       "      <td>1.026890e+05</td>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.300000e+01</td>\n",
       "      <td>8.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.565812e+06</td>\n",
       "      <td>1.543850e+05</td>\n",
       "      <td>2.300000e+01</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.600000e+01</td>\n",
       "      <td>1.500000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.421083e+06</td>\n",
       "      <td>2.062090e+05</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>2.300000e+01</td>\n",
       "      <td>3.000000e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           order_id       user_id  order_number  order_day_of_week  \\\n",
       "count  3.421083e+06  3.421083e+06  3.421083e+06       3.421083e+06   \n",
       "mean   1.710542e+06  1.029782e+05  1.715486e+01       2.776219e+00   \n",
       "std    9.875817e+05  5.953372e+04  1.773316e+01       2.046829e+00   \n",
       "min    1.000000e+00  1.000000e+00  1.000000e+00       0.000000e+00   \n",
       "25%    8.552715e+05  5.139400e+04  5.000000e+00       1.000000e+00   \n",
       "50%    1.710542e+06  1.026890e+05  1.100000e+01       3.000000e+00   \n",
       "75%    2.565812e+06  1.543850e+05  2.300000e+01       5.000000e+00   \n",
       "max    3.421083e+06  2.062090e+05  1.000000e+02       6.000000e+00   \n",
       "\n",
       "       order_hour_of_day  days_since_prior_order  \n",
       "count       3.421083e+06            3.421083e+06  \n",
       "mean        1.345202e+01            1.111484e+01  \n",
       "std         4.226088e+00            8.924952e+00  \n",
       "min         0.000000e+00            0.000000e+00  \n",
       "25%         1.000000e+01            5.000000e+00  \n",
       "50%         1.300000e+01            8.000000e+00  \n",
       "75%         1.600000e+01            1.500000e+01  \n",
       "max         2.300000e+01            3.000000e+01  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Set the path to the project directory\n",
    "path = r'C:\\Users\\sudee\\OneDrive\\Documents\\Python Scripts\\Instacart Basket Analysis'\n",
    "\n",
    "# Define column data types to avoid mixed-type data issues\n",
    "dtypes = {\n",
    "    'order_id': 'int64',\n",
    "    'user_id': 'int64',\n",
    "    'order_number': 'int64',\n",
    "    'order_day_of_week': 'int64',\n",
    "    'order_hour_of_day': 'int64',\n",
    "    'days_since_prior_order': 'float64'\n",
    "}\n",
    "\n",
    "# Import datasets with explicit data types\n",
    "df_ords = pd.read_csv(os.path.join(path, '02 Data', 'Prepared Data', 'orders_wrangled.csv'), dtype=dtypes)\n",
    "\n",
    "# Section 1: Run df.describe() on df_ords and document findings\n",
    "df_ords.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d2dcd0-149a-48d2-825c-bca84505fa83",
   "metadata": {},
   "source": [
    "### Observations from df.describe() on df_ords\n",
    "- The min value for 'order_hour_of_day' is 0, which is expected.\n",
    "- The max value for 'order_hour_of_day' is 23, which is within the expected range (0-23).\n",
    "- The min value for 'days_since_prior_order' is 0, which makes sense as an order can be placed the same day.\n",
    "- The max value for 'days_since_prior_order' is 30, which seems reasonable for tracking orders over a month.\n",
    "- The statistics do not show any obvious anomalies, so no immediate concerns are observed here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c62181c1-b3b1-44cf-9f9f-2b338bc06b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for mixed-type data in df_ords...\n",
      "Mixed type found in column: order_id\n",
      "Mixed type found in column: user_id\n",
      "Mixed type found in column: order_number\n",
      "Mixed type found in column: order_day_of_week\n",
      "Mixed type found in column: order_hour_of_day\n",
      "Mixed type found in column: days_since_prior_order\n"
     ]
    }
   ],
   "source": [
    "# Section 2: Check for mixed-type data in df_ords\n",
    "print(\"Checking for mixed-type data in df_ords...\")\n",
    "for col in df_ords.columns.tolist():\n",
    "    # Check if the type of the first element is different from the rest of the column\n",
    "    weird = (df_ords[col].apply(type) != type(df_ords[col].iloc[0])).any()\n",
    "    if weird:\n",
    "        print(f'Mixed type found in column: {col}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfd6c50-bb47-40e4-941e-9ae68a7691a9",
   "metadata": {},
   "source": [
    "### Observations from Mixed-Type Data Check on df_ords\n",
    "- No mixed-type data was found in any columns of df_ords, indicating that the data types are consistent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "00cc61c8-395f-483f-9f3b-7f617053e219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in df_ords:\n",
      "order_id                  0\n",
      "user_id                   0\n",
      "order_number              0\n",
      "order_day_of_week         0\n",
      "order_hour_of_day         0\n",
      "days_since_prior_order    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Section 3: Check for missing values in df_ords\n",
    "missing_values_ords = df_ords.isnull().sum()\n",
    "print(\"Missing values in df_ords:\")\n",
    "print(missing_values_ords)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5bcbfb-f40d-40c1-acf0-002860e074fc",
   "metadata": {},
   "source": [
    "### Observations from Missing Values Check on df_ords\n",
    "- The 'days_since_prior_order' column has 206,209 missing values.\n",
    "- No other columns have missing values.\n",
    "- Missing values in 'days_since_prior_order' likely occur for first-time orders where there is no prior order to reference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9439a1a1-56a8-4116-bcf2-fde0411d4f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after treatment:\n",
      "order_id                  0\n",
      "user_id                   0\n",
      "order_number              0\n",
      "order_day_of_week         0\n",
      "order_hour_of_day         0\n",
      "days_since_prior_order    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Section 4: Address missing values in df_ords\n",
    "df_ords['days_since_prior_order'] = df_ords['days_since_prior_order'].fillna(df_ords['days_since_prior_order'].mean())\n",
    "print(\"Missing values after treatment:\")\n",
    "print(df_ords.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b27d82-5528-4af6-9cfb-4c6daa591a6d",
   "metadata": {},
   "source": [
    "### Observations After Addressing Missing Values in df_ords\n",
    "- Missing values in 'days_since_prior_order' have been filled with the column's mean value.\n",
    "- This method was chosen to retain all rows and avoid losing data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7c26daf6-5b6c-4487-892e-5a7212857bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows in df_ords: 0\n"
     ]
    }
   ],
   "source": [
    "# Section 5: Check for duplicate values in df_ords\n",
    "duplicates_ords = df_ords.duplicated().sum()\n",
    "print(f\"Number of duplicate rows in df_ords: {duplicates_ords}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a38446-d731-4927-a2ee-0804df60d95e",
   "metadata": {},
   "source": [
    "### Observations from Duplicate Values Check on df_ords\n",
    "- No duplicate rows were found in df_ords.\n",
    "- This indicates that there are no exact duplicate entries in the orders data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d09ad022-b98f-484f-aad2-c214598586a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after removing duplicates: 3421083\n"
     ]
    }
   ],
   "source": [
    "# Section 6: Remove duplicate rows in df_ords\n",
    "df_ords_clean = df_ords.drop_duplicates()\n",
    "print(f\"Number of rows after removing duplicates: {df_ords_clean.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbcaa32-5be4-474c-89d3-833c40e4ab0e",
   "metadata": {},
   "source": [
    "### Observations After Removing Duplicates in df_ords\n",
    "- Since no duplicates were found, the number of rows remains the same after the operation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "afe541b3-f369-4815-a512-9e5b194ae6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 7: Export the cleaned data\n",
    "df_ords_clean.to_csv(os.path.join(path, '02 Data', 'Prepared Data', 'orders_checked.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "95dd78f4-9118-4bbf-9e32-6033f7fa4bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if C:\\Users\\sudee\\OneDrive\\Documents\\Python Scripts\\Instacart Basket Analysis\\02 Data\\Prepared Data\\orders_checked_clean.csv exists...\n",
      "C:\\Users\\sudee\\OneDrive\\Documents\\Python Scripts\\Instacart Basket Analysis\\02 Data\\Prepared Data\\orders_checked_clean.csv exists.\n",
      "Checking if C:\\Users\\sudee\\OneDrive\\Documents\\Python Scripts\\Instacart Basket Analysis\\02 Data\\Prepared Data\\products_checked_clean.csv exists...\n",
      "C:\\Users\\sudee\\OneDrive\\Documents\\Python Scripts\\Instacart Basket Analysis\\02 Data\\Prepared Data\\products_checked_clean.csv exists.\n",
      "Checking if C:\\Users\\sudee\\OneDrive\\Documents\\Python Scripts\\Instacart Basket Analysis\\02 Data\\Prepared Data\\orders_products_combined.csv exists...\n",
      "C:\\Users\\sudee\\OneDrive\\Documents\\Python Scripts\\Instacart Basket Analysis\\02 Data\\Prepared Data\\orders_products_combined.csv exists.\n",
      "df_orders shape: (3421083, 6)\n",
      "df_products shape: (49688, 5)\n",
      "df_orders_products_combined shape: (6, 13)\n",
      "Checking for mixed-type data in df_prods...\n",
      "Missing values in df_prods:\n",
      "product_id       0\n",
      "product_name     0\n",
      "aisle_id         0\n",
      "department_id    0\n",
      "prices           0\n",
      "dtype: int64\n",
      "Missing values after treatment:\n",
      "product_id       0\n",
      "product_name     0\n",
      "aisle_id         0\n",
      "department_id    0\n",
      "prices           0\n",
      "dtype: int64\n",
      "Number of duplicate rows in df_prods: 0\n",
      "Number of rows after removing duplicates: 49688\n",
      "           order_id       user_id  order_number  order_day_of_week  \\\n",
      "count  3.421083e+06  3.421083e+06  3.421083e+06       3.421083e+06   \n",
      "mean   1.710542e+06  1.029782e+05  1.715486e+01       2.776219e+00   \n",
      "std    9.875817e+05  5.953372e+04  1.773316e+01       2.046829e+00   \n",
      "min    1.000000e+00  1.000000e+00  1.000000e+00       0.000000e+00   \n",
      "25%    8.552715e+05  5.139400e+04  5.000000e+00       1.000000e+00   \n",
      "50%    1.710542e+06  1.026890e+05  1.100000e+01       3.000000e+00   \n",
      "75%    2.565812e+06  1.543850e+05  2.300000e+01       5.000000e+00   \n",
      "max    3.421083e+06  2.062090e+05  1.000000e+02       6.000000e+00   \n",
      "\n",
      "       order_hour_of_day  days_since_prior_order  \n",
      "count       3.421083e+06            3.421083e+06  \n",
      "mean        1.345202e+01            1.111484e+01  \n",
      "std         4.226088e+00            8.924952e+00  \n",
      "min         0.000000e+00            0.000000e+00  \n",
      "25%         1.000000e+01            5.000000e+00  \n",
      "50%         1.300000e+01            8.000000e+00  \n",
      "75%         1.600000e+01            1.500000e+01  \n",
      "max         2.300000e+01            3.000000e+01  \n",
      "\n",
      "# Analysis and Observations:\n",
      "\n",
      "1. 'order_number': The minimum value is 1, which is expected for the first order. However, the maximum value is 100, which seems unusually high for the number of orders placed by a single user.\n",
      "2. 'order_day_of_week': The values range from 0 to 6, representing the days of the week (0 = Saturday, 1 = Sunday, etc.).\n",
      "3. 'order_hour_of_day': The values range from 0 to 23, which is within the expected range for hours in a day.\n",
      "4. 'days_since_prior_order': This column represents the number of days since the last order. The minimum value is 0 (valid for same-day orders), but the maximum value is 30, which could indicate a data entry error or a business rule.\n",
      "\n",
      "\n",
      "Checking for mixed-type data in df_ords...\n",
      "Missing values in df_ords:\n",
      "order_id                  0\n",
      "user_id                   0\n",
      "order_number              0\n",
      "order_day_of_week         0\n",
      "order_hour_of_day         0\n",
      "days_since_prior_order    0\n",
      "dtype: int64\n",
      "Missing values after treatment:\n",
      "order_id                  0\n",
      "user_id                   0\n",
      "order_number              0\n",
      "order_day_of_week         0\n",
      "order_hour_of_day         0\n",
      "days_since_prior_order    0\n",
      "dtype: int64\n",
      "Number of duplicate rows in df_ords: 0\n",
      "Number of rows after removing duplicates: 3421083\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Path to the project folder\n",
    "project_path = r'C:\\Users\\sudee\\OneDrive\\Documents\\Python Scripts\\Instacart Basket Analysis'\n",
    "\n",
    "# Paths to the data files\n",
    "orders_checked_path = os.path.join(project_path, '02 Data', 'Prepared Data', 'orders_checked_clean.csv')\n",
    "products_checked_path = os.path.join(project_path, '02 Data', 'Prepared Data', 'products_checked_clean.csv')\n",
    "orders_products_combined_path = os.path.join(project_path, '02 Data', 'Prepared Data', 'orders_products_combined.csv')\n",
    "\n",
    "# Function to check if the file exists\n",
    "def check_file_exists(filepath):\n",
    "    print(f\"Checking if {filepath} exists...\")\n",
    "    if not os.path.exists(filepath):\n",
    "        raise FileNotFoundError(f'{filepath} not found. Please check the file path or previous export steps.')\n",
    "    print(f\"{filepath} exists.\")\n",
    "\n",
    "# Check if the necessary files exist\n",
    "check_file_exists(orders_checked_path)\n",
    "check_file_exists(products_checked_path)\n",
    "check_file_exists(orders_products_combined_path)\n",
    "\n",
    "# Load the datasets\n",
    "df_orders = pd.read_csv(orders_checked_path)\n",
    "df_products = pd.read_csv(products_checked_path)\n",
    "df_orders_products_combined = pd.read_csv(orders_products_combined_path)\n",
    "\n",
    "# Check the shapes of the datasets\n",
    "print('df_orders shape:', df_orders.shape)\n",
    "print('df_products shape:', df_products.shape)\n",
    "print('df_orders_products_combined shape:', df_orders_products_combined.shape)\n",
    "\n",
    "# Task 4.5: Data Consistency Checks\n",
    "\n",
    "# Section 1: Perform Consistency Checks on df_prods\n",
    "\n",
    "# Step 1: Check for mixed-type data in df_prods\n",
    "print(\"Checking for mixed-type data in df_prods...\")\n",
    "for col in df_products.columns.tolist():\n",
    "    weird = (df_products[[col]].map(type) != df_products[[col]].iloc[0].map(type)).any(axis=1)\n",
    "    if len(df_products[weird]) > 0:\n",
    "        print(f'Mixed type found in column: {col}')\n",
    "\n",
    "# Step 2: Check for missing values in df_prods\n",
    "missing_values_prods = df_products.isnull().sum()\n",
    "print(\"Missing values in df_prods:\")\n",
    "print(missing_values_prods)\n",
    "\n",
    "# Step 3: Address missing values in df_prods\n",
    "df_products['product_name'] = df_products['product_name'].fillna('Unknown')\n",
    "print(\"Missing values after treatment:\")\n",
    "print(df_products.isnull().sum())\n",
    "\n",
    "# Step 4: Check for duplicate values in df_prods\n",
    "duplicates_prods = df_products.duplicated().sum()\n",
    "print(f\"Number of duplicate rows in df_prods: {duplicates_prods}\")\n",
    "\n",
    "# Step 5: Remove duplicate rows in df_prods\n",
    "df_prods_clean = df_products.drop_duplicates()\n",
    "print(f\"Number of rows after removing duplicates: {df_prods_clean.shape[0]}\")\n",
    "\n",
    "# Step 6: Export the cleaned data\n",
    "df_prods_clean.to_csv(os.path.join(project_path, '02 Data', 'Prepared Data', 'products_checked_clean.csv'), index=False)\n",
    "\n",
    "# Section 2: Perform Consistency Checks on df_ords\n",
    "\n",
    "# Step 1: Run df.describe() on df_ords\n",
    "df_ords_describe = df_orders.describe()\n",
    "print(df_ords_describe)\n",
    "\n",
    "# Markdown cell for observations\n",
    "observations = \"\"\"\n",
    "# Analysis and Observations:\n",
    "\n",
    "1. 'order_number': The minimum value is 1, which is expected for the first order. However, the maximum value is 100, which seems unusually high for the number of orders placed by a single user.\n",
    "2. 'order_day_of_week': The values range from 0 to 6, representing the days of the week (0 = Saturday, 1 = Sunday, etc.).\n",
    "3. 'order_hour_of_day': The values range from 0 to 23, which is within the expected range for hours in a day.\n",
    "4. 'days_since_prior_order': This column represents the number of days since the last order. The minimum value is 0 (valid for same-day orders), but the maximum value is 30, which could indicate a data entry error or a business rule.\n",
    "\n",
    "\"\"\"\n",
    "print(observations)\n",
    "\n",
    "# Step 2: Check for mixed-type data in df_ords\n",
    "print(\"Checking for mixed-type data in df_ords...\")\n",
    "for col in df_orders.columns.tolist():\n",
    "    weird = (df_orders[[col]].map(type) != df_orders[[col]].iloc[0].map(type)).any(axis=1)\n",
    "    if len(df_orders[weird]) > 0:\n",
    "        print(f'Mixed type found in column: {col}')\n",
    "\n",
    "# Step 3: Check for missing values in df_ords\n",
    "missing_values_ords = df_orders.isnull().sum()\n",
    "print(\"Missing values in df_ords:\")\n",
    "print(missing_values_ords)\n",
    "\n",
    "# Step 4: Address missing values in df_ords\n",
    "df_orders['days_since_prior_order'] = df_orders['days_since_prior_order'].fillna(df_orders['days_since_prior_order'].mean())\n",
    "print(\"Missing values after treatment:\")\n",
    "print(df_orders.isnull().sum())\n",
    "\n",
    "# Step 5: Check for duplicate values in df_ords\n",
    "duplicates_ords = df_orders.duplicated().sum()\n",
    "print(f\"Number of duplicate rows in df_ords: {duplicates_ords}\")\n",
    "\n",
    "# Step 6: Remove duplicate rows in df_ords\n",
    "df_ords_clean = df_orders.drop_duplicates()\n",
    "print(f\"Number of rows after removing duplicates: {df_ords_clean.shape[0]}\")\n",
    "\n",
    "# Step 7: Export the cleaned data\n",
    "df_ords_clean.to_csv(os.path.join(project_path, '02 Data', 'Prepared Data', 'orders_checked_clean.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f93256e-f7bd-4523-aed1-a26ff24c9aa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
