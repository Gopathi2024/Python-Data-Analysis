{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4df5e8eb-bd42-4f61-9c06-684a1d9774f4",
   "metadata": {},
   "source": [
    "# Aggregating and Grouping Data\r\n",
    "\r\n",
    "## Introduction\r\n",
    "In this task, we perform aggregation and grouping on our dataset to derive insights based on customer behavior and product categories. Specifically, we:\r\n",
    "1. Import the merged orders and products data.\r\n",
    "2. Perform various aggregation operations.\r\n",
    "3. Group data by customer and product attributes.\r\n",
    "4. Export the final dataframe.\r\n",
    "\r\n",
    "## Step 1: Load and Inspect the Data\r\n",
    "We start by loading the combined orders and products dataframe and inspecting its shape and columns.\r\n",
    "\r\n",
    "## Step 2: Aggregate Data by Product\r\n",
    "We perform aggregation operations to find the total orders and mean prices for each product.\r\n",
    "\r\n",
    "## Step 3: Group Data by Customer\r\n",
    "We group the data by customer to derive insights such as the total spend and average order size.\r\n",
    "\r\n",
    "## Step 4: Group Data by Product Category\r\n",
    "We ensure that the `department_id` column is present and group the data by department to analyze trends.\r\n",
    "\r\n",
    "## Step 5: Create Additional Derived Metrics\r\n",
    "We create additional derived metrics such as the frequency of reorder for each product.\r\n",
    "\r\n",
    "## Step 6: Export the Final Dataframe\r\n",
    "Finally, we export the aggregated data as a pickle file for further analysis.\r\n",
    "\r\n",
    "## Step 7: Create Spending Flag for Each User\r\n",
    "We create a spending flag for each user based on the average price across all their orders.\r\n",
    "\r\n",
    "## Step 8: Create Order Frequency Flag\r\n",
    "We create an order frequency flag to categorize customers based on their ordering behavior.\r\n",
    "\r\n",
    "## Step 9: Clean and Structure the Notebook\r\n",
    "We ensure the notebook is clean, well-structured, and all code is well commented.\r\n",
    "\r\n",
    "## Summary\r\n",
    "In this task, we:\r\n",
    "1. Loaded the merged orders and products data.\r\n",
    "2. Performed various aggregation operations to derive insights.\r\n",
    "3. Grouped data by customer and product attributes.\r\n",
    "4. Created additional derived metrics.\r\n",
    "5. Created spending and order frequency flags for users.\r\n",
    "6. Exported the final aggregated dataframe.\r\n",
    " the final aggregated dataframe.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "485e8649-3e2e-4844-85e9-2506c4c2ec0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined DataFrame shape: (32435059, 13)\n",
      "   order_id  user_id  order_number  order_day_of_week  order_hour_of_day  \\\n",
      "0   2539329        1             1                  2                  8   \n",
      "1   2539329        1             1                  2                  8   \n",
      "2   2539329        1             1                  2                  8   \n",
      "3   2539329        1             1                  2                  8   \n",
      "4   2539329        1             1                  2                  8   \n",
      "\n",
      "   days_since_prior_order  product_id  add_to_cart_order  reordered  prices  \\\n",
      "0               11.114836         196                  1          0     9.0   \n",
      "1               11.114836       14084                  2          0    12.5   \n",
      "2               11.114836       12427                  3          0     4.4   \n",
      "3               11.114836       26088                  4          0     4.7   \n",
      "4               11.114836       26405                  5          0     1.0   \n",
      "\n",
      "         price_label     busiest_day busiest_period_of_day  \n",
      "0  Mid-range product  Regularly busy        Average orders  \n",
      "1  Mid-range product  Regularly busy        Average orders  \n",
      "2  Low-range product  Regularly busy        Average orders  \n",
      "3  Low-range product  Regularly busy        Average orders  \n",
      "4  Low-range product  Regularly busy        Average orders  \n",
      "Index(['order_id', 'user_id', 'order_number', 'order_day_of_week',\n",
      "       'order_hour_of_day', 'days_since_prior_order', 'product_id',\n",
      "       'add_to_cart_order', 'reordered', 'prices', 'price_label',\n",
      "       'busiest_day', 'busiest_period_of_day'],\n",
      "      dtype='object')\n",
      "Columns after merge to include 'department_id': Index(['order_id', 'user_id', 'order_number', 'order_day_of_week',\n",
      "       'order_hour_of_day', 'days_since_prior_order', 'product_id',\n",
      "       'add_to_cart_order', 'reordered', 'prices', 'price_label',\n",
      "       'busiest_day', 'busiest_period_of_day', 'department_id'],\n",
      "      dtype='object')\n",
      "Product Aggregations:\n",
      "   product_id  total_orders  mean_price\n",
      "0           1          1852         5.8\n",
      "1           2            90         9.3\n",
      "2           3           277         4.5\n",
      "3           4           329        10.5\n",
      "4           5            15         4.3\n",
      "Customer Aggregations:\n",
      "   user_id  total_spend  avg_order_size\n",
      "0        1        375.7              59\n",
      "1        2       1465.6             195\n",
      "2        3        721.4              88\n",
      "3        4        147.7              18\n",
      "4        5        340.0              37\n",
      "Department Aggregations:\n",
      "   department_id  total_orders  mean_price\n",
      "0            1.0       2236432    7.741434\n",
      "1            2.0         36291    6.990934\n",
      "2            3.0       1176787    7.864723\n",
      "3            4.0       9479291    7.981708\n",
      "4            5.0        153696    8.143701\n",
      "Reorder Frequency for Products:\n",
      "   product_id  reorder_frequency\n",
      "0         196           0.776480\n",
      "1       14084           0.810982\n",
      "2       12427           0.740735\n",
      "3       26088           0.539041\n",
      "4       26405           0.441516\n",
      "Spending Flag for Users:\n",
      "   user_id  mean_price spending_flag\n",
      "0        1    6.367797   Low spender\n",
      "1        2    7.515897   Low spender\n",
      "2        3    8.197727   Low spender\n",
      "3        4    8.205556   Low spender\n",
      "4        5    9.189189   Low spender\n",
      "Order Frequency Flag for Users:\n",
      "   user_id  median_days_since_prior order_frequency_flag\n",
      "0        1                20.000000     Regular customer\n",
      "1        2                13.000000     Regular customer\n",
      "2        3                11.057418     Regular customer\n",
      "3        4                17.000000     Regular customer\n",
      "4        5                11.114836     Regular customer\n",
      "Final DataFrame exported to C:\\Users\\sudee\\OneDrive\\Documents\\Python Scripts\\Instacart Basket Analysis\\02 Data\\Prepared Data\\final_aggregated_orders_products.pkl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Path to the project folder\n",
    "project_path = r'C:\\Users\\sudee\\OneDrive\\Documents\\Python Scripts\\Instacart Basket Analysis'\n",
    "\n",
    "# File paths\n",
    "combined_data_path = os.path.join(project_path, '02 Data', 'Prepared Data', 'orders_products_combined_with_labels.pkl')\n",
    "df_products_path = os.path.join(project_path, '02 Data', 'Prepared Data', 'products_checked_clean.csv')\n",
    "\n",
    "# Load the combined dataset\n",
    "df_combined = pd.read_pickle(combined_data_path)\n",
    "\n",
    "# Check the shape and head of the dataframe\n",
    "print(\"Combined DataFrame shape:\", df_combined.shape)\n",
    "print(df_combined.head())\n",
    "print(df_combined.columns)\n",
    "\n",
    "# Load the products data\n",
    "df_products = pd.read_csv(df_products_path)\n",
    "\n",
    "# Ensure 'department_id' is present by merging with products data if necessary\n",
    "df_combined = df_combined.merge(df_products[['product_id', 'department_id']], on='product_id', how='left')\n",
    "\n",
    "# Check if 'department_id' is now in df_combined\n",
    "print(\"Columns after merge to include 'department_id':\", df_combined.columns)\n",
    "\n",
    "# Step 2: Aggregate data to find the total orders and mean prices for each product\n",
    "product_aggregations = df_combined.groupby('product_id').agg(\n",
    "    total_orders=('order_id', 'count'),\n",
    "    mean_price=('prices', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# Check the result of aggregation\n",
    "print(\"Product Aggregations:\")\n",
    "print(product_aggregations.head())\n",
    "\n",
    "# Step 3: Group data by customer to find total spend and average order size\n",
    "customer_aggregations = df_combined.groupby('user_id').agg(\n",
    "    total_spend=('prices', 'sum'),\n",
    "    avg_order_size=('order_id', 'count')\n",
    ").reset_index()\n",
    "\n",
    "# Check the result of customer aggregation\n",
    "print(\"Customer Aggregations:\")\n",
    "print(customer_aggregations.head())\n",
    "\n",
    "# Step 4: Group data by department to find total orders and mean prices\n",
    "department_aggregations = df_combined.groupby('department_id').agg(\n",
    "    total_orders=('order_id', 'count'),\n",
    "    mean_price=('prices', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# Check the result of department aggregation\n",
    "print(\"Department Aggregations:\")\n",
    "print(department_aggregations.head())\n",
    "\n",
    "# Step 5: Create additional derived metrics\n",
    "df_combined['reorder_frequency'] = df_combined.groupby('product_id')['reordered'].transform('mean')\n",
    "\n",
    "# Check the result of derived metrics\n",
    "print(\"Reorder Frequency for Products:\")\n",
    "print(df_combined[['product_id', 'reorder_frequency']].drop_duplicates().head())\n",
    "\n",
    "# Step 7: Create spending flag for each user\n",
    "user_spending = df_combined.groupby('user_id').agg(mean_price=('prices', 'mean')).reset_index()\n",
    "\n",
    "# Define spending flag\n",
    "user_spending['spending_flag'] = user_spending['mean_price'].apply(\n",
    "    lambda x: 'Low spender' if x < 10 else 'High spender'\n",
    ")\n",
    "\n",
    "# Merge spending flag back to the main dataframe\n",
    "df_combined = df_combined.merge(user_spending[['user_id', 'spending_flag']], on='user_id', how='left')\n",
    "\n",
    "# Check the spending flag\n",
    "print(\"Spending Flag for Users:\")\n",
    "print(user_spending.head())\n",
    "\n",
    "# Step 8: Create order frequency flag\n",
    "user_order_frequency = df_combined.groupby('user_id').agg(median_days_since_prior=('days_since_prior_order', 'median')).reset_index()\n",
    "\n",
    "# Define order frequency flag\n",
    "def order_frequency_flag(days):\n",
    "    if days > 20:\n",
    "        return 'Non-frequent customer'\n",
    "    elif days > 10:\n",
    "        return 'Regular customer'\n",
    "    else:\n",
    "        return 'Frequent customer'\n",
    "\n",
    "user_order_frequency['order_frequency_flag'] = user_order_frequency['median_days_since_prior'].apply(order_frequency_flag)\n",
    "\n",
    "# Merge order frequency flag back to the main dataframe\n",
    "df_combined = df_combined.merge(user_order_frequency[['user_id', 'order_frequency_flag']], on='user_id', how='left')\n",
    "\n",
    "# Check the order frequency flag\n",
    "print(\"Order Frequency Flag for Users:\")\n",
    "print(user_order_frequency.head())\n",
    "\n",
    "# Step 10: Export the final dataframe as a pickle file\n",
    "final_data_path = os.path.join(project_path, '02 Data', 'Prepared Data', 'final_aggregated_orders_products.pkl')\n",
    "df_combined.to_pickle(final_data_path)\n",
    "print(f\"Final DataFrame exported to {final_data_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a64d226-d464-41d3-9fae-391e2229dd9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
